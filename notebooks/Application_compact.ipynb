{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.app.name': 'oh-my-git_final', 'driverMemory': '2000M', 'executorMemory': '8G', 'executorCores': 8, 'numExecutors': 16}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>9130</td><td>application_1589299642358_3694</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3694/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3694_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9171</td><td>application_1589299642358_3738</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3738/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3738_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9177</td><td>application_1589299642358_3744</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3744/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3744_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9188</td><td>application_1589299642358_3755</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3755/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster066.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3755_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9191</td><td>application_1589299642358_3758</td><td>pyspark</td><td>dead</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3758/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster054.iccluster.epfl.ch:8188/applicationhistory/logs/iccluster070.iccluster.epfl.ch:45454/container_e06_1589299642358_3758_01_000001/container_e06_1589299642358_3758_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9192</td><td>application_1589299642358_3759</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3759/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster070.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3759_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9194</td><td>application_1589299642358_3761</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3761/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster067.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3761_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9195</td><td>application_1589299642358_3762</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3762/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster071.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3762_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9196</td><td>application_1589299642358_3763</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3763/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3763_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9199</td><td>application_1589299642358_3766</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3766/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster066.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3766_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9200</td><td>application_1589299642358_3767</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3767/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3767_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9202</td><td>application_1589299642358_3769</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3769/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster066.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3769_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9203</td><td>application_1589299642358_3770</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3770/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster067.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3770_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9204</td><td>application_1589299642358_3771</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3771/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster067.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3771_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9205</td><td>application_1589299642358_3772</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3772/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3772_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9206</td><td>application_1589299642358_3773</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3773/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster067.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3773_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9207</td><td>application_1589299642358_3774</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3774/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3774_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9210</td><td>application_1589299642358_3777</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3777/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3777_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9212</td><td>application_1589299642358_3779</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3779/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3779_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9214</td><td>application_1589299642358_3781</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3781/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3781_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9216</td><td>application_1589299642358_3783</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3783/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3783_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9217</td><td>application_1589299642358_3784</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3784/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3784_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9221</td><td>application_1589299642358_3788</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3788/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster066.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3788_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9222</td><td>application_1589299642358_3789</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3789/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster071.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3789_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9225</td><td>application_1589299642358_3792</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3792/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3792_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9226</td><td>application_1589299642358_3793</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3793/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3793_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9228</td><td>application_1589299642358_3795</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3795/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster067.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3795_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9229</td><td>application_1589299642358_3796</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3796/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3796_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9230</td><td>application_1589299642358_3797</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3797/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3797_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9231</td><td>application_1589299642358_3798</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3798/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3798_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9232</td><td>application_1589299642358_3799</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3799/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster067.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3799_01_000001/ebouille\">Link</a></td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure\n",
    "{\"conf\": {\n",
    "    \"spark.app.name\":\"oh-my-git_final\",\n",
    "     \"driverMemory\": \"2000M\",\n",
    "    \"executorMemory\": \"8G\",\n",
    "    \"executorCores\": 8,\n",
    "    \"numExecutors\": 16\n",
    "}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>9233</td><td>application_1589299642358_3800</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3800/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster066.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3800_01_000001/ebouille\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All utilities in a single cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can collapse the cell below if you want to hide the libraries and functions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All utilities are loaded successfully."
     ]
    }
   ],
   "source": [
    "# Import relevant libraries\n",
    "from geopy import distance\n",
    "import pyspark.sql.types as T\n",
    "import pyspark.sql.functions  as F\n",
    "from pyspark.sql.window import Window\n",
    "import datetime\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from itertools import islice, tee, izip, combinations\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import math\n",
    "\n",
    "# Some constants\n",
    "zurichHB = (47.378177, 8.540192)\n",
    "cleveland_oh = (49.378177, 9.540192)\n",
    "\n",
    "# Useful user-defined functions\n",
    "@F.udf(T.DoubleType())\n",
    "def getDistToZurich(lat,lon):\n",
    "    \"\"\"\n",
    "    Get distance to the Zurich HB in kilometers.\n",
    "    \"\"\"\n",
    "    zurichHB = (47.378177, 8.540192)\n",
    "    geo = (lat,lon)\n",
    "    return distance.distance(zurichHB, geo).km\n",
    "\n",
    "@F.udf(T.ArrayType(\n",
    "       T.ArrayType(T.StructType([\n",
    "    T.StructField(\"pair1\", T.StringType(), False),\n",
    "    T.StructField(\"pair2\", T.StringType(), False)\n",
    "]))))\n",
    "def pairs(stop_ids,stop_sequences,arrival_times,departure_times):\n",
    "    \"\"\"\n",
    "    Print the journey information in pairs.\n",
    "    \"\"\"\n",
    "    stop_id_pairs = list(combinations(stop_ids,2))\n",
    "    stop_sequence_pairs = list(combinations(stop_sequences,2))\n",
    "    arrival_time_pairs = list(combinations(arrival_times,2))\n",
    "    departure_time_pairs = list(combinations(departure_times,2))\n",
    "    return [stop_id_pairs,stop_sequence_pairs,arrival_time_pairs,departure_time_pairs]\n",
    "\n",
    "@F.udf(T.BooleanType())\n",
    "def time_interval_udf(arrival_time_schedule,transfer_arrival_time):\n",
    "    \"\"\"\n",
    "    Get a 2 minute time interval in order to do find relevant vehicles in the SBB data.\n",
    "    \"\"\"\n",
    "    if arrival_time_schedule == \"\":\n",
    "        return False\n",
    "    ah = transfer_arrival_time.split(\":\")[0]\n",
    "    am = transfer_arrival_time.split(\":\")[1]\n",
    "    a = datetime.datetime(2019, 1, 1, int(ah), int(am))\n",
    "    \n",
    "    atsh = arrival_time_schedule.split(\":\")[0]\n",
    "    atsm = arrival_time_schedule.split(\":\")[1]\n",
    "    ats = datetime.datetime(2019, 1, 1, int(atsh), int(atsm))\n",
    "    \n",
    "    #Allow 120 seconds time difference\n",
    "    if abs(ats-a).total_seconds() <= 120:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "@F.udf(T.DoubleType())\n",
    "def getDist(lat1,lon1,lat2,lon2):\n",
    "    \"\"\"\n",
    "    Get distance between two coordinates in terms of meters.\n",
    "    \"\"\"\n",
    "    geo1 = (lat1,lon1)\n",
    "    geo2 = (lat2,lon2)\n",
    "    dist = distance.distance(geo1, geo2).m\n",
    "    return dist\n",
    "joineds = spark.read.parquet(\"user/boecuego/backtrace_df.parquet\")\n",
    "#joineds.cache()\n",
    "#joineds.take(1)\n",
    "unioned_df_unique = spark.read.parquet(\"user/boecuego/graph_df.parquet\")\n",
    "pd_df = unioned_df_unique.toPandas()\n",
    "mygraph = nx.from_pandas_edgelist(pd_df, 'stop_id1', 'stop_id2',[\"cost\",\"types\"])\n",
    "#sbb_grouped_delay = sbb_inradius_wostops.withColumn(\"delay\",F.floor(timeDiff/60)).groupBy(\"stop_id\",\"delay\").count()\n",
    "# sbb_grouped_delay.write.parquet(\"user/boecuego/sbb_stops_time_grouped.parquet\")\n",
    "\n",
    "sbb_grouped_delay = spark.read.parquet(\"user/boecuego/sbb_stops_time_grouped.parquet\")\n",
    "#!!! TO DO !!!!!\n",
    "#Filter weekends, public holidays etc\n",
    "#!!! TO DO !!!!!\n",
    "def find_prob(stop_id,arrival_time_schedule):\n",
    "    timeDiff = (F.unix_timestamp('arrival_time_real', format=\"HH:mm:ss\")\n",
    "            - F.unix_timestamp('arrival_time_schedule', format=\"HH:mm\"))\n",
    "    delays = sbb_grouped_delay.filter((F.col('stop_id') == stop_id) & time_interval_udf(F.col('arrival_time_schedule'), F.lit(arrival_time_schedule)))\n",
    "    #Find the total num\n",
    "    #total_num = delays.groupBy().sum(\"count\").collect()[0][0]\n",
    "    #print(total_num)\n",
    "    delays_pd = delays.toPandas()\n",
    "    total_num = sum(delays_pd[\"count\"].values)\n",
    "    delays_pd[\"percentage\"] = delays_pd[\"count\"].map(lambda x:(x/float(total_num))*100)\n",
    "    return delays_pd\n",
    "#Find the k shortest paths\n",
    "def k_shortest_paths(G, source, target, k, weight):\n",
    "    return list(islice(nx.shortest_simple_paths(G, source, target, weight=weight), k))\n",
    "\n",
    "#This is a helper to get pairs in a list\n",
    "def pairwise(iterable):\n",
    "    \"s -> (s0,s1), (s1,s2), (s2, s3), ...\"\n",
    "    a, b = tee(iterable)\n",
    "    next(b, None)\n",
    "    return izip(a, b)\n",
    "#When converting a date to string this is a helper\n",
    "def append_zero(x):\n",
    "    if len(str(x)) == 1:\n",
    "        return \"0\"+str(x)\n",
    "    return str(x)\n",
    "#Helper to remove adjecent walks\n",
    "def remove_adjecent_walks(paths):\n",
    "    no_adjecentwalk =[]\n",
    "    for pr in paths:\n",
    "        check = True\n",
    "        for p1,p2 in pairwise(pairwise(pr)):\n",
    "\n",
    "            if mygraph[p1[0]][p1[1]][\"types\"] == [\"walk\"] and mygraph[p2[0]][p2[1]][\"types\"] == [\"walk\"]:\n",
    "                #print(counter)\n",
    "                check = False\n",
    "\n",
    "        if check:\n",
    "            no_adjecentwalk.append(pr)\n",
    "    return no_adjecentwalk\n",
    "\n",
    "#Helper to reverse route\n",
    "def get_reverse_route(paths):\n",
    "    reversed_routes  = []\n",
    "    for route in paths:\n",
    "        lst = []\n",
    "        for a in pairwise(route):\n",
    "            lst.append(a)\n",
    "        lst_reversed = lst[::-1]\n",
    "        reversed_routes.append(lst_reversed)\n",
    "    return reversed_routes\n",
    "notPossible = datetime.datetime(1999,1,1,12,12,0,0)\n",
    "def find_possible_routes(reversed_routes,current_timez,cut_off_time):\n",
    "    \n",
    "    shorts = []\n",
    "    longs = []\n",
    "    printouts = []\n",
    "    notpossibles = []\n",
    "    for route in reversed_routes:\n",
    "        break_loop = False\n",
    "        current_time = current_timez\n",
    "        current_trip_id = \"\"\n",
    "        \n",
    "        route_with_timetable = []\n",
    "        trip = []\n",
    "        prints  = []\n",
    "        actual_prints=[]\n",
    "        for p1,p2 in route:\n",
    "            #p2 arrival\n",
    "            #p1 departure\n",
    "            if mygraph[p1][p2][\"types\"] == [\"walk\"]:\n",
    "                prints.append(\"Transfer with walking\")\n",
    "                prints.append((\"after_walk\",current_time))\n",
    "                cost = mygraph[p1][p2][\"cost\"]\n",
    "                if cost > 0:\n",
    "                    current_time  = current_time - datetime.timedelta(minutes=cost-10)#-2\n",
    "                else:\n",
    "                    current_time = current_time\n",
    "                prints.append((\"before_walk\",current_time))\n",
    "                current_trip_id=\"\"\n",
    "                \n",
    "                actual_prints.append(\"Walk from \"+p1+\" ----to----> \"+p2+\" for \"+str(cost-10)+\" minutes.\")\n",
    "                prints.append((p1,p2))\n",
    "                continue\n",
    "            else:\n",
    "                #Get current times hour and minute\n",
    "                hour = current_time.hour\n",
    "                minute = current_time.minute\n",
    "\n",
    "                #Convert it to string\n",
    "                strtime = append_zero(hour)+\":\"+append_zero(minute)+\":00\"\n",
    "\n",
    "                #Get closest trip to current time with matching stop_ids\n",
    "                if current_trip_id != \"\":\n",
    "                    trip = joineds.filter(F.col(\"trip_id\") == current_trip_id)\\\n",
    "                    .filter(\"stop_id1 == '\"+p1+\"'\"+\" AND \"+\"stop_id2 == '\"+p2+\"'\").take(1)\n",
    "               #trip = df_trip_network_reasonable2.filter(\"prev_stop_id == '\"+p1+\"'\"+\" AND \"+\"stop_id == '\"+p2+\"'\").filter(\"arrival_time <='\"+strtime+\"'\").sort(F.desc(\"arrival_time\")).take(1)[0]\n",
    "\n",
    "                #If previous trip_id was different from this trip's id then put 2 minute waiting time\n",
    "                if trip == [] or current_trip_id == \"\":\n",
    "\n",
    "                    #2 min waiting\n",
    "                    if current_trip_id != \"\":\n",
    "                        current_time = current_time - datetime.timedelta(minutes = 2)\n",
    "                        prints.append(\"Transfer\")\n",
    "\n",
    "\n",
    "                    #Get hours, minutes\n",
    "                    hour = current_time.hour\n",
    "                    minute = current_time.minute\n",
    "                    strtime = append_zero(hour)+\":\"+append_zero(minute)+\":00\"\n",
    "\n",
    "                    #With new current time get new trip\n",
    "                    trip = joineds.filter(\"stop_id1 == '\"+p1+\"'\"+\" AND \"+\"stop_id2 == '\"+p2+\"'\").filter(\"arrival_time2 <='\"+strtime+\"'\").sort(F.desc(\"arrival_time2\")).take(1)\n",
    "                    #update current trip_id\n",
    "                try:\n",
    "                    trip = trip[0]\n",
    "                except:\n",
    "                    #print(\"Encountered a route that is not possible currently\",(p1,p2))\n",
    "                    current_time = notPossible\n",
    "                    break\n",
    "                current_trip_id  = trip.trip_id\n",
    "\n",
    "                #Update current time\n",
    "                prtstr = \"Take trip: \"+trip.trip_id+\" from \"+p1+\" departing at \"+trip.departure_time1+\" ------------> to \"+p2+\" arriving at \"+trip.arrival_time2\n",
    "                actual_prints.append(prtstr)\n",
    "                prints.append((trip.trip_id,trip.arrival_time1,trip.departure_time1,trip.arrival_time2,trip.departure_time2))\n",
    "                hms = trip.departure_time1.split(\":\")\n",
    "                h = int(hms[0])\n",
    "                m = int(hms[1])\n",
    "                current_time = datetime.datetime(2019,1,1,h,m,0,0)\n",
    "\n",
    "            prints.append((p1,p2))\n",
    "            if break_loop:\n",
    "                prints = []\n",
    "                break\n",
    "        if current_time >= cut_off_time:\n",
    "            shorts.append(prints)\n",
    "            shorts.append(current_time)\n",
    "            shorts.append(\"---------------------------------------------------------------\")\n",
    "            printouts.append(actual_prints)\n",
    "        elif current_time == notPossible:\n",
    "            notpossibles.append(prints)\n",
    "            notpossibles.append(current_time)\n",
    "            notpossibles.append(\"---------------------------------------------------------------\")\n",
    "        else:\n",
    "            longs.append(prints)\n",
    "            longs.append(\"---------------------------------------------------------------\")\n",
    "    return shorts,longs,printouts\n",
    "##### !!!!!!! TO CHECK !!!!!!!!\n",
    "# This is currently not checking the probabiliy of desired arival time Also need to check that\n",
    "#!!!!!!! TO CHECK !!!!!!!!\n",
    "confidence_level = 0.98\n",
    "def calculate_probabilities(desired_arrival_time,best_routes, best_routes_print,confidence_level):\n",
    "    counter = 0\n",
    "    for r,printroute in zip(best_routes,best_routes_print):\n",
    "        overall_prob = 1.\n",
    "        \n",
    "        printornot = []\n",
    "        for i in range(len(r)):\n",
    "            # This case corresponds to the Pr[Arriving the final station in time] case\n",
    "            # That is why the index is zero and the final means of travelling should not be walking but a public transport\n",
    "            if i == 0 and r[i]!=\"Transfer with walking\":\n",
    "                las_arrival_time = r[i][3]\n",
    "                ah = las_arrival_time.split(\":\")[0]\n",
    "                am = las_arrival_time.split(\":\")[1]\n",
    "                a = datetime.datetime(2019, 1, 1, int(ah), int(am))\n",
    "                last_station = r[i+1][1]\n",
    "                \n",
    "                allowed_delay = (desired_arrival_time-a).total_seconds()/60\n",
    "                prob_dist =find_prob(last_station,las_arrival_time[:-3])\n",
    "                probability_to_catch = sum(prob_dist[prob_dist[\"delay\"]<= allowed_delay].percentage.values)\n",
    "                overall_prob = (float(overall_prob)*float(probability_to_catch))/100.\n",
    "                printornot.append(\"Prob to arrive on time: \"+str(probability_to_catch))\n",
    "\n",
    "            try:\n",
    "                if r[i] == \"Transfer with walking\":\n",
    "\n",
    "                    transfer_departure_time = r[i-2][2]\n",
    "                    dh = transfer_departure_time.split(\":\")[0]\n",
    "                    dm = transfer_departure_time.split(\":\")[1]\n",
    "                    d = datetime.datetime(2019, 1, 1, int(dh), int(dm))\n",
    "                    #think this\n",
    "                    transfer_station =  r[i+5][1].split(\":\")[0]\n",
    "\n",
    "                    walking_min = (r[i+1][1] - r[i+2][1]).total_seconds()/60\n",
    "\n",
    "                    #think this\n",
    "                    transfer_arrival_time = r[i+4][3]\n",
    "            \n",
    "\n",
    "                    ah = transfer_arrival_time.split(\":\")[0]\n",
    "                    am = transfer_arrival_time.split(\":\")[1]\n",
    "                    a = datetime.datetime(2019, 1, 1, int(ah), int(am))\n",
    "                    allowed_delay = (d-a).total_seconds()/60 - walking_min\n",
    "                    #print(transfer_station,transfer_arrival_time)\n",
    "                    prob_dist =find_prob(transfer_station,transfer_arrival_time[:-3])\n",
    "\n",
    "                    probability_to_catch = sum(prob_dist[prob_dist[\"delay\"]<= allowed_delay].percentage.values)\n",
    "                    \n",
    "                    printornot.append(\"Probability to catch trip \"+r[i-2][0]+\" with \"+str(walking_min)+\" min walking  : \"+str(probability_to_catch))\n",
    "                    \n",
    "                    overall_prob = (float(overall_prob)*float(probability_to_catch))/100.\n",
    "                \n",
    "                elif r[i] == \"Transfer\":\n",
    "                    transfer_departure_time = r[i-2][2]\n",
    "                    dh = transfer_departure_time.split(\":\")[0]\n",
    "                    dm = transfer_departure_time.split(\":\")[1]\n",
    "                    d = datetime.datetime(2019, 1, 1, int(dh), int(dm))\n",
    "                    transfer_station =  r[i-1][1]\n",
    "                    \n",
    "                    transfer_arrival_time = r[i+1][3]\n",
    "                    \n",
    "                    ah = transfer_arrival_time.split(\":\")[0]\n",
    "                    am = transfer_arrival_time.split(\":\")[1]\n",
    "                    a = datetime.datetime(2019, 1, 1, int(ah), int(am))\n",
    "                    allowed_delay = (d-a).total_seconds()/60\n",
    "                    prob_dist =find_prob(transfer_station,transfer_arrival_time[:-3])\n",
    "                    \n",
    "                    probability_to_catch = sum(prob_dist[prob_dist[\"delay\"]<= allowed_delay].percentage.values)\n",
    "                    printornot.append(\"Probability to catch trip \"+r[i-2][0]+\" : \"+str(probability_to_catch))\n",
    "                    overall_prob = (float(overall_prob)*float(probability_to_catch))/100.\n",
    "\n",
    "            except:\n",
    "                print(\"-\")\n",
    "        \n",
    "        if overall_prob > confidence_level:\n",
    "            counter +=1\n",
    "            print(\"*\"*100)\n",
    "            print(\"Overal probability: \"+str(overall_prob))\n",
    "            print(\"Probabilities: \")\n",
    "            for prt in printornot:\n",
    "                print \"\\t\"+prt\n",
    "            print(\"Route: \")\n",
    "            for rou in printroute:\n",
    "                print \"\\t\"+rou\n",
    "            #print(\"Probability matches the confidence level, we can select this route.\")\n",
    "        else:\n",
    "            warning = 1\n",
    "            #for rou in printroute:\n",
    "            #    print rou\n",
    "            #print(\"WARNING: Confidence level is lower than the required amount! Do not select this route!\")\n",
    "    print str(counter)+\" routes found out of \"+str(len(best_routes))+\" best routes , if you want more please enter lower confidence\"\n",
    "        \n",
    "def schedule_planner(src, tgt, desired_arrival_time, confidence_level):\n",
    "    start = datetime.datetime.now()\n",
    "    \n",
    "    confidence_level=float(confidence_level)\n",
    "    \n",
    "    src_main = src.split(\":\")[0]\n",
    "    tgt_main = tgt.split(\":\")[0]\n",
    "    counter = 0\n",
    "    paths = []\n",
    "    for node in mygraph.nodes:\n",
    "        if src_main in node:\n",
    "            counter+=1\n",
    "\n",
    "    if counter > 1:\n",
    "        k = 5\n",
    "    else:\n",
    "        k=50\n",
    "    for node in mygraph.nodes:\n",
    "        if src_main in node:\n",
    "            p = k_shortest_paths(mygraph, node, tgt,k,weight = \"cost\")\n",
    "            for x in p:\n",
    "                paths.append(x)\n",
    "    no_adjecentwalk = remove_adjecent_walks(paths)\n",
    "    reversed_routes  = get_reverse_route(no_adjecentwalk)\n",
    "    \n",
    "    hm = desired_arrival_time.split(':')\n",
    "    h = hm[0]\n",
    "    m = hm[1]\n",
    "    #This is arrival_time\n",
    "    current_time = datetime.datetime(2019,1,1,int(h),int(m),0,0)\n",
    "    cut_off_time = current_time - datetime.timedelta(minutes=60)\n",
    "    \n",
    "    notPossible = datetime.datetime(1999,1,1,12,12,0,0)\n",
    "    good_routes,bad_routes,printouts = find_possible_routes(reversed_routes,current_time,cut_off_time)\n",
    "    \n",
    "    \"\"\"\n",
    "    for element in good_routes:\n",
    "        if type(element) == type([]):\n",
    "            for r in element:\n",
    "                print(r)\n",
    "        else:\n",
    "            print element\n",
    "            \n",
    "    for element in bad_routes:\n",
    "        if type(element) == type([]):\n",
    "            for r in element:\n",
    "                print(r)\n",
    "        else:\n",
    "            print element\n",
    "    \"\"\"\n",
    "            \n",
    "    maxt = datetime.datetime(2019, 1, 1, 0,0)\n",
    "    index = -1\n",
    "    start_times  = []\n",
    "    for i,t in enumerate(good_routes):\n",
    "        if type(t) == type(datetime.datetime(2019, 1, 1, 11, 56)):\n",
    "            start_times.append((t,i))\n",
    "            if t > maxt:\n",
    "                maxt = t\n",
    "                index = i\n",
    "    start_times_reversed = sorted(start_times, key=lambda tup: tup[0],reverse=True)\n",
    "    best_routes = []\n",
    "    best_routes_print = [] \n",
    "\n",
    "    for time,index in start_times_reversed[:10]:\n",
    "        route = good_routes[index-1:index]\n",
    "        best_routes.append(route[0])\n",
    "        route_print = printouts[index/3]\n",
    "        best_routes_print.append(route_print)\n",
    "    \"\"\"\n",
    "    for r in best_routes_print:\n",
    "        print(\"******\"*10)\n",
    "        for x in r:\n",
    "            print x\n",
    "    for r in best_routes:\n",
    "        print(\"******\"*10)\n",
    "        for x in r:\n",
    "            print x\"\"\"\n",
    "    \n",
    "    print('*'*100)\n",
    "    print('PROBABILITIES')\n",
    "            \n",
    "    only_routes = good_routes[::3]\n",
    "    calculate_probabilities(current_time,best_routes,best_routes_print, confidence_level)\n",
    "    \n",
    "    end = datetime.datetime.now()\n",
    "    print('*'*100)\n",
    "    print(\"Running time:\", (end-start).total_seconds(), \"seconds.\")\n",
    "    \n",
    "print(\"All utilities are loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a59bac5390040ce84e0910df4770125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='8591184', description='src'), Text(value='8591244', description='tgt'), Text…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.troll(src, tgt, desired_arrival_time, confidence_level)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%local\n",
    "#src = \"8591184\"  #\"8503000\"\n",
    "#tgt  =  \"8591244\" #\"8591049\"\n",
    "\n",
    "\n",
    "def troll(src, tgt, desired_arrival_time, confidence_level):\n",
    "    # To push it to the spark\n",
    "    confidence_level = str(confidence_level)\n",
    "    \n",
    "    get_ipython().push(\"src\")\n",
    "    get_ipython().push(\"tgt\")\n",
    "    get_ipython().push(\"desired_arrival_time\")\n",
    "    get_ipython().push(\"confidence_level\")\n",
    "    get_ipython().run_cell_magic('send_to_spark','-i src -t str -n src' , ' ')\n",
    "    get_ipython().run_cell_magic('send_to_spark','-i tgt -t str -n tgt' , ' ')\n",
    "    get_ipython().run_cell_magic('send_to_spark','-i desired_arrival_time -t str -n desired_arrival_time' , ' ')\n",
    "    get_ipython().run_cell_magic('send_to_spark','-i confidence_level -t str -n confidence_level' , ' ')\n",
    "\n",
    "    \n",
    "    get_ipython().run_cell_magic('spark', '', 'schedule_planner(src, tgt, desired_arrival_time, confidence_level)') \n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets \n",
    "func_handle = interact_manual(troll, src='8591184', tgt='8591244', desired_arrival_time='12:30',\n",
    "                                confidence_level=widgets.FloatSlider(min=0.0, max=1.0, step=1e-2, value=0.90))\n",
    "func_handle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "matched_trips = spark.read.parquet(\"user/boecuego/matched_trips2.parquet\") \n",
    "mmm = matched_trips.filter(\"LENGTH(trips_stop_ids) > 15 AND sample_stop_ids != '%%' \").groupBy(\"trips_trip_id\").agg(F.collect_set(\"sbb_trip_id\").alias(\"possible_match\"))\n",
    "stop_matches = map(lambda row: row.asDict(), mmm.collect())\n",
    "dict_matches = {match['trips_trip_id']: match[\"possible_match\"] for match in stop_matches}\n",
    "sbb_inradius = spark.read.parquet(\"user/boecuego/sbb_inradius_13_17_trips_select.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "Except\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "Except\n",
      "**************************************************\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "**************************************************\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "Except\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "Except\n",
      "**************************************************\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "**************************************************\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "**************************************************\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "**************************************************\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "**************************************************\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "Except\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "Except\n",
      "**************************************************\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "**************************************************\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "**************************************************\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "**************************************************\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "**************************************************\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "Except\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "Except\n",
      "**************************************************\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "**************************************************\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "**************************************************\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "**************************************************\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "**************************************************\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "Except\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "Except\n",
      "**************************************************\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "**************************************************\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "**************************************************\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "**************************************************\n",
      "**************************************************\n",
      "**************************************************\n",
      "Validation from the real past data:\n",
      "0.9375\n",
      "**************************************************\n",
      "Time to run the validation code in seconds:\n",
      "1515.88118"
     ]
    }
   ],
   "source": [
    "t1=datetime.datetime.now()\n",
    "#Trips are from above result \n",
    "trips = [\"1460.TA.26-10-j19-1.11.R\",\"2698.TA.26-31-j19-1.17.H\",\"1386.TA.26-8-C-j19-1.8.R\"]\n",
    "departs = [\"12:12:00\",\"12:03:00\",\"11:59:00\"]\n",
    "arrives = [\"12:25:00\",\"12:09:00\",\"12:00:00\"]\n",
    "allz = zip(pairwise(trips),pairwise(departs),pairwise(arrives))\n",
    "\n",
    "days = [append_zero(str(x))+\".05.2019\" for x in range(1,30)]\n",
    "weekdayslst = [\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\"]\n",
    "\n",
    "weekdays = [x if datetime.datetime.strptime(x, '%d.%m.%Y').strftime('%A') in weekdayslst else \"\" for x in days]\n",
    "weekdays= filter(None,weekdays)\n",
    "\n",
    "catched_counter = 0\n",
    "counter = 0\n",
    "for day in weekdays:\n",
    "    print(\"*\"*50)\n",
    "    sbd = sbb_inradius.filter(F.col(\"date\")==day)\n",
    "    for trip,depart,arrive in reversed(allz):\n",
    "        print(\"- -\"*30)\n",
    "        ilkduraktankalkan = dict_matches[trip[1]]\n",
    "        ikinciduraktankalkan = dict_matches[trip[0]]\n",
    "        try:\n",
    "            ilkininin_ikinciye_varisi = sbd.filter((F.col(\"trip_id\").isin(ilkduraktankalkan)) \\\n",
    "                                                            &(F.substring(F.col(\"schedule_arrival\"),12,100) == arrive[1][:-3])).take(1)[0]\n",
    "            ikincinin_kalkisi = sbd.filter((F.col(\"trip_id\").isin(ikinciduraktankalkan)) \\\n",
    "                                                            &(F.substring(F.col(\"schedule_dep\"),12,100) == depart[0][:-3])).take(1)[0]\n",
    "\n",
    "            hm = ilkininin_ikinciye_varisi.arrival_time_real.split(':')\n",
    "            h = hm[0]\n",
    "            m = hm[1]\n",
    "            s = hm[2]\n",
    "            aa = datetime.datetime(2019,1,1,int(h),int(m),int(s),0)\n",
    "\n",
    "            hm = ikincinin_kalkisi.departure_time_real.split(':')\n",
    "            h = hm[0]\n",
    "            m = hm[1]\n",
    "            s = hm[2]\n",
    "            ad = datetime.datetime(2019,1,1,int(h),int(m),int(s),0)\n",
    "\n",
    "            window = (ad-aa).total_seconds()\n",
    "            #print(window/60)\n",
    "            counter +=1\n",
    "            if window >=0:\n",
    "                catched_counter+=1\n",
    "\n",
    "\n",
    "        except:\n",
    "            print \"Except\"\n",
    "t2=datetime.datetime.now()\n",
    "print(\"*\"*50)\n",
    "print(\"*\"*50)\n",
    "print(\"*\"*50)\n",
    "print(\"Validation from the real past data:\")\n",
    "print(float(catched_counter)/float(counter))\n",
    "print(\"*\"*50)\n",
    "print(\"Time to run the validation code in seconds:\")\n",
    "print((t2-t1).total_seconds())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

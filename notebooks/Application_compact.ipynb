{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.app.name': 'oh-my-git_final', 'driverMemory': '2000M', 'executorMemory': '8G', 'executorCores': 4, 'numExecutors': 20}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>8642</td><td>application_1589299642358_3167</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3167/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3167_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8739</td><td>application_1589299642358_3264</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3264/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3264_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8751</td><td>application_1589299642358_3277</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3277/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3277_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8766</td><td>application_1589299642358_3292</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3292/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3292_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8771</td><td>application_1589299642358_3299</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3299/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster066.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3299_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8788</td><td>application_1589299642358_3316</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3316/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3316_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8794</td><td>application_1589299642358_3322</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3322/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster067.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3322_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8795</td><td>application_1589299642358_3323</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3323/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster066.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3323_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8797</td><td>application_1589299642358_3325</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3325/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3325_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8798</td><td>application_1589299642358_3326</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3326/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3326_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8799</td><td>application_1589299642358_3327</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3327/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster071.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3327_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8800</td><td>application_1589299642358_3328</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3328/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster066.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3328_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8801</td><td>application_1589299642358_3329</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3329/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3329_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8802</td><td>application_1589299642358_3330</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3330/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3330_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8803</td><td>application_1589299642358_3331</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3331/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster071.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3331_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8805</td><td>application_1589299642358_3333</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3333/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3333_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8806</td><td>application_1589299642358_3334</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3334/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3334_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8808</td><td>application_1589299642358_3336</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3336/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3336_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8809</td><td>application_1589299642358_3337</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3337/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster066.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3337_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8810</td><td>application_1589299642358_3338</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3338/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster067.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3338_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8811</td><td>application_1589299642358_3339</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3339/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster066.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3339_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8815</td><td>application_1589299642358_3345</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3345/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3345_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>8816</td><td>application_1589299642358_3346</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3346/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster070.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3346_01_000001/ebouille\">Link</a></td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure\n",
    "{\"conf\": {\n",
    "    \"spark.app.name\":\"oh-my-git_final\",\n",
    "     \"driverMemory\": \"2000M\",\n",
    "    \"executorMemory\": \"8G\",\n",
    "    \"executorCores\": 4,\n",
    "    \"numExecutors\": 20\n",
    "}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>8817</td><td>application_1589299642358_3347</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3347/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster067.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3347_01_000001/ebouille\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import relevant libraries\n",
    "from geopy import distance\n",
    "import pyspark.sql.types as T\n",
    "import pyspark.sql.functions  as F\n",
    "from pyspark.sql.window import Window\n",
    "import datetime\n",
    "import networkx as nxsche\n",
    "import pandas as pd\n",
    "from itertools import islice, tee, izip, combinations\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Some constants\n",
    "zurichHB = (47.378177, 8.540192)\n",
    "cleveland_oh = (49.378177, 9.540192)\n",
    "\n",
    "# Useful user-defined functions\n",
    "@F.udf(T.DoubleType())\n",
    "def getDistToZurich(lat,lon):\n",
    "    \"\"\"\n",
    "    Get distance to the Zurich HB in kilometers.\n",
    "    \"\"\"\n",
    "    zurichHB = (47.378177, 8.540192)\n",
    "    geo = (lat,lon)\n",
    "    return distance.distance(zurichHB, geo).km\n",
    "\n",
    "@F.udf(T.ArrayType(\n",
    "       T.ArrayType(T.StructType([\n",
    "    T.StructField(\"pair1\", T.StringType(), False),\n",
    "    T.StructField(\"pair2\", T.StringType(), False)\n",
    "]))))\n",
    "def pairs(stop_ids,stop_sequences,arrival_times,departure_times):\n",
    "    \"\"\"\n",
    "    Print the journey information in pairs.\n",
    "    \"\"\"\n",
    "    stop_id_pairs = list(combinations(stop_ids,2))\n",
    "    stop_sequence_pairs = list(combinations(stop_sequences,2))\n",
    "    arrival_time_pairs = list(combinations(arrival_times,2))\n",
    "    departure_time_pairs = list(combinations(departure_times,2))\n",
    "    return [stop_id_pairs,stop_sequence_pairs,arrival_time_pairs,departure_time_pairs]\n",
    "\n",
    "@F.udf(T.BooleanType())\n",
    "def time_interval_udf(arrival_time_schedule,transfer_arrival_time):\n",
    "    \"\"\"\n",
    "    Get a 2 minute time interval in order to do find relevant vehicles in the SBB data.\n",
    "    \"\"\"\n",
    "    if arrival_time_schedule == \"\":\n",
    "        return False\n",
    "    ah = transfer_arrival_time.split(\":\")[0]\n",
    "    am = transfer_arrival_time.split(\":\")[1]\n",
    "    a = datetime.datetime(2019, 1, 1, int(ah), int(am))\n",
    "    \n",
    "    atsh = arrival_time_schedule.split(\":\")[0]\n",
    "    atsm = arrival_time_schedule.split(\":\")[1]\n",
    "    ats = datetime.datetime(2019, 1, 1, int(atsh), int(atsm))\n",
    "    \n",
    "    #Allow 120 seconds time difference\n",
    "    if abs(ats-a).total_seconds() <= 120:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "@F.udf(T.DoubleType())\n",
    "def getDist(lat1,lon1,lat2,lon2):\n",
    "    \"\"\"\n",
    "    Get distance between two coordinates in terms of meters.\n",
    "    \"\"\"\n",
    "    geo1 = (lat1,lon1)\n",
    "    geo2 = (lat2,lon2)\n",
    "    dist = distance.distance(geo1, geo2).m\n",
    "    return dist\n",
    "joineds = spark.read.parquet(\"user/boecuego/backtrace_df.parquet\")\n",
    "joineds.cache()\n",
    "joineds.take(1)\n",
    "unioned_df_unique = spark.read.parquet(\"user/boecuego/graph_df.parquet\")\n",
    "pd_df = unioned_df_unique.toPandas()\n",
    "mygraph = nx.from_pandas_edgelist(pd_df, 'stop_id1', 'stop_id2',[\"cost\",\"types\"])\n",
    "#sbb_grouped_delay = sbb_inradius_wostops.withColumn(\"delay\",F.floor(timeDiff/60)).groupBy(\"stop_id\",\"delay\").count()\n",
    "# sbb_grouped_delay.write.parquet(\"user/boecuego/sbb_stops_time_grouped.parquet\")\n",
    "\n",
    "sbb_grouped_delay = spark.read.parquet(\"user/boecuego/sbb_stops_time_grouped.parquet\")\n",
    "#!!! TO DO !!!!!\n",
    "#Filter weekends, public holidays etc\n",
    "#!!! TO DO !!!!!\n",
    "def find_prob(stop_id,arrival_time_schedule):\n",
    "    timeDiff = (F.unix_timestamp('arrival_time_real', format=\"HH:mm:ss\")\n",
    "            - F.unix_timestamp('arrival_time_schedule', format=\"HH:mm\"))\n",
    "    delays = sbb_grouped_delay.filter((F.col('stop_id') == stop_id) & time_interval_udf(F.col('arrival_time_schedule'), F.lit(arrival_time_schedule)))\n",
    "    #Find the total num\n",
    "    #total_num = delays.groupBy().sum(\"count\").collect()[0][0]\n",
    "    #print(total_num)\n",
    "    delays_pd = delays.toPandas()\n",
    "    total_num = sum(delays_pd[\"count\"].values)\n",
    "    delays_pd[\"percentage\"] = delays_pd[\"count\"].map(lambda x:(x/float(total_num))*100)\n",
    "    return delays_pd\n",
    "#Find the k shortest paths\n",
    "def k_shortest_paths(G, source, target, k, weight):\n",
    "    return list(islice(nx.shortest_simple_paths(G, source, target, weight=weight), k))\n",
    "\n",
    "#This is a helper to get pairs in a list\n",
    "def pairwise(iterable):\n",
    "    \"s -> (s0,s1), (s1,s2), (s2, s3), ...\"\n",
    "    a, b = tee(iterable)\n",
    "    next(b, None)\n",
    "    return izip(a, b)\n",
    "#When converting a date to string this is a helper\n",
    "def append_zero(x):\n",
    "    if len(str(x)) == 1:\n",
    "        return \"0\"+str(x)\n",
    "    return str(x)\n",
    "#Helper to remove adjecent walks\n",
    "def remove_adjecent_walks(paths):\n",
    "    no_adjecentwalk =[]\n",
    "    for pr in paths:\n",
    "        check = True\n",
    "        for p1,p2 in pairwise(pairwise(pr)):\n",
    "\n",
    "            if mygraph[p1[0]][p1[1]][\"types\"] == [\"walk\"] and mygraph[p2[0]][p2[1]][\"types\"] == [\"walk\"]:\n",
    "                #print(counter)\n",
    "                check = False\n",
    "\n",
    "        if check:\n",
    "            no_adjecentwalk.append(pr)\n",
    "    return no_adjecentwalk\n",
    "\n",
    "#Helper to reverse route\n",
    "def get_reverse_route(paths):\n",
    "    reversed_routes  = []\n",
    "    for route in paths:\n",
    "        lst = []\n",
    "        for a in pairwise(route):\n",
    "            lst.append(a)\n",
    "        lst_reversed = lst[::-1]\n",
    "        reversed_routes.append(lst_reversed)\n",
    "    return reversed_routes\n",
    "notPossible = datetime.datetime(1999,1,1,12,12,0,0)\n",
    "def find_possible_routes(reversed_routes,current_timez,cut_off_time):\n",
    "    \n",
    "    shorts = []\n",
    "    longs = []\n",
    "    notpossibles = []\n",
    "    for route in reversed_routes:\n",
    "        break_loop = False\n",
    "        current_time = current_timez\n",
    "        current_trip_id = \"\"\n",
    "        \n",
    "        route_with_timetable = []\n",
    "        trip = []\n",
    "        prints  = []\n",
    "        for p1,p2 in route:\n",
    "            #p2 arrival\n",
    "            #p1 departure\n",
    "            if mygraph[p1][p2][\"types\"] == [\"walk\"]:\n",
    "                prints.append(\"Transfer with walking\")\n",
    "                prints.append((\"after_walk\",current_time))\n",
    "                cost = mygraph[p1][p2][\"cost\"]\n",
    "                if cost > 0:\n",
    "                    current_time  = current_time - datetime.timedelta(minutes=cost-10)#-2\n",
    "                else:\n",
    "                    current_time = current_time\n",
    "                prints.append((\"before_walk\",current_time))\n",
    "                current_trip_id=\"\"\n",
    "                prints.append((p1,p2))\n",
    "                continue\n",
    "            else:\n",
    "                #Get current times hour and minute\n",
    "                hour = current_time.hour\n",
    "                minute = current_time.minute\n",
    "\n",
    "                #Convert it to string\n",
    "                strtime = append_zero(hour)+\":\"+append_zero(minute)+\":00\"\n",
    "\n",
    "                #Get closest trip to current time with matching stop_ids\n",
    "                if current_trip_id != \"\":\n",
    "                    trip = joineds.filter(F.col(\"trip_id\") == current_trip_id)\\\n",
    "                    .filter(\"stop_id1 == '\"+p1+\"'\"+\" AND \"+\"stop_id2 == '\"+p2+\"'\").take(1)\n",
    "               #trip = df_trip_network_reasonable2.filter(\"prev_stop_id == '\"+p1+\"'\"+\" AND \"+\"stop_id == '\"+p2+\"'\").filter(\"arrival_time <='\"+strtime+\"'\").sort(F.desc(\"arrival_time\")).take(1)[0]\n",
    "\n",
    "                #If previous trip_id was different from this trip's id then put 2 minute waiting time\n",
    "                if trip == [] or current_trip_id == \"\":\n",
    "\n",
    "                    #2 min waiting\n",
    "                    if current_trip_id != \"\":\n",
    "                        current_time = current_time - datetime.timedelta(minutes = 2)\n",
    "                        prints.append(\"Transfer\")\n",
    "\n",
    "\n",
    "                    #Get hours, minutes\n",
    "                    hour = current_time.hour\n",
    "                    minute = current_time.minute\n",
    "                    strtime = append_zero(hour)+\":\"+append_zero(minute)+\":00\"\n",
    "\n",
    "                    #With new current time get new trip\n",
    "                    trip = joineds.filter(\"stop_id1 == '\"+p1+\"'\"+\" AND \"+\"stop_id2 == '\"+p2+\"'\").filter(\"arrival_time2 <='\"+strtime+\"'\").sort(F.desc(\"arrival_time2\")).take(1)\n",
    "                    #update current trip_id\n",
    "                try:\n",
    "                    trip = trip[0]\n",
    "                except:\n",
    "                    print(\"Encountered a route that is not possible currently\",(p1,p2))\n",
    "                    current_time = notPossible\n",
    "                    break\n",
    "                current_trip_id  = trip.trip_id\n",
    "\n",
    "                #Update current time\n",
    "                prints.append((trip.trip_id,trip.arrival_time1,trip.departure_time1,trip.arrival_time2,trip.departure_time2))\n",
    "                hms = trip.departure_time1.split(\":\")\n",
    "                h = int(hms[0])\n",
    "                m = int(hms[1])\n",
    "                current_time = datetime.datetime(2019,1,1,h,m,0,0)\n",
    "\n",
    "            prints.append((p1,p2))\n",
    "            if break_loop:\n",
    "                prints = []\n",
    "                break\n",
    "        if current_time >= cut_off_time:\n",
    "            shorts.append(prints)\n",
    "            shorts.append(current_time)\n",
    "            shorts.append(\"---------------------------------------------------------------\")\n",
    "        elif current_time == notPossible:\n",
    "            notpossibles.append(prints)\n",
    "            notpossibles.append(current_time)\n",
    "            notpossibles.append(\"---------------------------------------------------------------\")\n",
    "        else:\n",
    "            longs.append(prints)\n",
    "            longs.append(\"---------------------------------------------------------------\")\n",
    "    return shorts,longs\n",
    "##### !!!!!!! TO CHECK !!!!!!!!\n",
    "# This is currently not checking the probabiliy of desired arival time Also need to check that\n",
    "#!!!!!!! TO CHECK !!!!!!!!\n",
    "confidence_level = 0.98\n",
    "def calculate_probabilities(desired_arrival_time,best_routes, confidence_level):\n",
    "    \n",
    "    for r in best_routes:\n",
    "        overall_prob = 1\n",
    "        print(\"*\"*100)\n",
    "\n",
    "        for i in range(len(r)):\n",
    "            # This case corresponds to the Pr[Arriving the final station in time] case\n",
    "            # That is why the index is zero and the final means of travelling should not be walking but a public transport\n",
    "            if i == 0 and r[i]!=\"Transfer with walking\":\n",
    "                las_arrival_time = r[i][3]\n",
    "                ah = las_arrival_time.split(\":\")[0]\n",
    "                am = las_arrival_time.split(\":\")[1]\n",
    "                a = datetime.datetime(2019, 1, 1, int(ah), int(am))\n",
    "                last_station = r[i+1][1]\n",
    "                \n",
    "                allowed_delay = (desired_arrival_time-a).total_seconds()/60\n",
    "                prob_dist =find_prob(last_station,las_arrival_time[:-3])\n",
    "                probability_to_catch = sum(prob_dist[prob_dist[\"delay\"]<= allowed_delay].percentage.values)\n",
    "                overall_prob = (overall_prob*probability_to_catch)/100\n",
    "                print(\"Prob to arrive on time: \",probability_to_catch)\n",
    "\n",
    "            try:\n",
    "                if r[i] == \"Transfer with walking\":\n",
    "\n",
    "                    transfer_departure_time = r[i-2][2]\n",
    "                    dh = transfer_departure_time.split(\":\")[0]\n",
    "                    dm = transfer_departure_time.split(\":\")[1]\n",
    "                    d = datetime.datetime(2019, 1, 1, int(dh), int(dm))\n",
    "                    #think this\n",
    "                    transfer_station =  r[i+5][1].split(\":\")[0]\n",
    "\n",
    "                    walking_min = (r[i+1][1] - r[i+2][1]).total_seconds()/60\n",
    "\n",
    "                    #think this\n",
    "                    transfer_arrival_time = r[i+4][3]\n",
    "            \n",
    "\n",
    "                    ah = transfer_arrival_time.split(\":\")[0]\n",
    "                    am = transfer_arrival_time.split(\":\")[1]\n",
    "                    a = datetime.datetime(2019, 1, 1, int(ah), int(am))\n",
    "                    allowed_delay = (d-a).total_seconds()/60 - walking_min\n",
    "                    print(transfer_station,transfer_arrival_time)\n",
    "                    prob_dist =find_prob(transfer_station,transfer_arrival_time[:-3])\n",
    "\n",
    "                    probability_to_catch = sum(prob_dist[prob_dist[\"delay\"]<= allowed_delay].percentage.values)\n",
    "                    print(\"For station \",transfer_station,\"probability to catch trip \",r[i-2][0],\" : with walking transfer probability\",\n",
    "                           probability_to_catch,\"departing at \",transfer_departure_time)\n",
    "                    print(\"Last vehicle arrived at: \",transfer_arrival_time)\n",
    "                    overall_prob = (overall_prob*probability_to_catch)/100\n",
    "                \n",
    "                elif r[i] == \"Transfer\":\n",
    "                    transfer_departure_time = r[i-2][2]\n",
    "                    dh = transfer_departure_time.split(\":\")[0]\n",
    "                    dm = transfer_departure_time.split(\":\")[1]\n",
    "                    d = datetime.datetime(2019, 1, 1, int(dh), int(dm))\n",
    "                    transfer_station =  r[i-1][1]\n",
    "                    \n",
    "                    transfer_arrival_time = r[i+1][3]\n",
    "                    \n",
    "                    ah = transfer_arrival_time.split(\":\")[0]\n",
    "                    am = transfer_arrival_time.split(\":\")[1]\n",
    "                    a = datetime.datetime(2019, 1, 1, int(ah), int(am))\n",
    "                    allowed_delay = (d-a).total_seconds()/60\n",
    "                    prob_dist =find_prob(transfer_station,transfer_arrival_time[:-3])\n",
    "                    \n",
    "                    probability_to_catch = sum(prob_dist[prob_dist[\"delay\"]<= allowed_delay].percentage.values)\n",
    "                    print(\"For station \",transfer_station,\"probability to catch trip \",r[i-2][0],\" :direct transfer probability\",\n",
    "                           probability_to_catch,\"departing at \",transfer_departure_time)\n",
    "                    print(\"Last vehicle arrived at: \",transfer_arrival_time)\n",
    "                    overall_prob = (overall_prob*probability_to_catch)/100\n",
    "\n",
    "            except:\n",
    "                print(\"Except\",r[i],\"First or last trip is walking so no transfer\")\n",
    "        print(\"Overal probability: \",overall_prob)\n",
    "        if overall_prob > confidence_level:\n",
    "            print(\"Probability matches the confidence level, we can select this route.\")\n",
    "        else:\n",
    "            print(\"WARNING: Confidence level is lower than the required amount! Do not select this route!\")\n",
    "def schedule_planner(src, tgt, desired_arrival_time, confidence_level):\n",
    "    start = datetime.datetime.now()\n",
    "    \n",
    "    confidence_level=float(confidence_level)\n",
    "    \n",
    "    src_main = src.split(\":\")[0]\n",
    "    tgt_main = tgt.split(\":\")[0]\n",
    "    counter = 0\n",
    "    paths = []\n",
    "    for node in mygraph.nodes:\n",
    "        if src_main in node:\n",
    "            counter+=1\n",
    "\n",
    "    if counter > 1:\n",
    "        k = 5\n",
    "    else:\n",
    "        k=50\n",
    "    for node in mygraph.nodes:\n",
    "        if src_main in node:\n",
    "            p = k_shortest_paths(mygraph, node, tgt,k,weight = \"cost\")\n",
    "            for x in p:\n",
    "                paths.append(x)\n",
    "    no_adjecentwalk = remove_adjecent_walks(paths)\n",
    "    reversed_routes  = get_reverse_route(no_adjecentwalk)\n",
    "    \n",
    "    hm = desired_arrival_time.split(':')\n",
    "    h = hm[0]\n",
    "    m = hm[1]\n",
    "    #This is arrival_time\n",
    "    current_time = datetime.datetime(2019,1,1,int(h),int(m),0,0)\n",
    "    cut_off_time = current_time - datetime.timedelta(minutes=60)\n",
    "    \n",
    "    notPossible = datetime.datetime(1999,1,1,12,12,0,0)\n",
    "    good_routes,bad_routes = find_possible_routes(reversed_routes,current_time,cut_off_time)\n",
    "    \n",
    "    \"\"\"\n",
    "    for element in good_routes:\n",
    "        if type(element) == type([]):\n",
    "            for r in element:\n",
    "                print(r)\n",
    "        else:\n",
    "            print element\n",
    "            \n",
    "    for element in bad_routes:\n",
    "        if type(element) == type([]):\n",
    "            for r in element:\n",
    "                print(r)\n",
    "        else:\n",
    "            print element\n",
    "    \"\"\"\n",
    "            \n",
    "    maxt = datetime.datetime(2019, 1, 1, 0,0)\n",
    "    index = -1\n",
    "    start_times  = []\n",
    "    for i,t in enumerate(good_routes):\n",
    "        if type(t) == type(datetime.datetime(2019, 1, 1, 11, 56)):\n",
    "            start_times.append((t,i))\n",
    "            if t > maxt:\n",
    "                maxt = t\n",
    "                index = i\n",
    "    start_times_reversed = sorted(start_times, key=lambda tup: tup[0],reverse=True)\n",
    "    best_routes = []\n",
    "    for time,index in start_times_reversed[:10]:\n",
    "        route = good_routes[index-1:index]\n",
    "        best_routes.append(route[0])\n",
    "        \n",
    "    for r in best_routes:\n",
    "        print(\"******\"*10)\n",
    "        for x in r:\n",
    "            print x\n",
    "            \n",
    "    print('*'*100)\n",
    "    print('PROBABILITIES')\n",
    "            \n",
    "    only_routes = good_routes[::3]\n",
    "    calculate_probabilities(current_time,best_routes, confidence_level)\n",
    "    \n",
    "    end = datetime.datetime.now()\n",
    "    print('*'*100)\n",
    "    print(\"Running time:\", (end-start).total_seconds(), \"seconds.\")\n",
    "    \n",
    "print(\"All utilities are loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b1aa8d8ef55444590cf2b06fd463b98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='8503000', description='src'), Text(value='8591049', description='tgt'), Text…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.troll(src, tgt, desired_arrival_time, confidence_level)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%local\n",
    "def troll(src, tgt, desired_arrival_time, confidence_level):\n",
    "    # To push it to the spark\n",
    "    confidence_level = str(confidence_level)\n",
    "    \n",
    "    get_ipython().push(\"src\")\n",
    "    get_ipython().push(\"tgt\")\n",
    "    get_ipython().push(\"desired_arrival_time\")\n",
    "    get_ipython().push(\"confidence_level\")\n",
    "    get_ipython().run_cell_magic('send_to_spark','-i src -t str -n src' , ' ')\n",
    "    get_ipython().run_cell_magic('send_to_spark','-i tgt -t str -n tgt' , ' ')\n",
    "    get_ipython().run_cell_magic('send_to_spark','-i desired_arrival_time -t str -n desired_arrival_time' , ' ')\n",
    "    get_ipython().run_cell_magic('send_to_spark','-i confidence_level -t str -n confidence_level' , ' ')\n",
    "\n",
    "    \n",
    "    get_ipython().run_cell_magic('spark', '', 'schedule_planner(src, tgt, desired_arrival_time, confidence_level)') \n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets \n",
    "func_handle = interact_manual(troll, src='8503000', tgt='8591049', desired_arrival_time='12:30',\n",
    "                                confidence_level=widgets.FloatSlider(min=0.0, max=1.0, step=1e-2, value=0.90))\n",
    "func_handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
